{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carbondioxide', 'greenhousegas', 'emissions', 'global', 'warming', 'fossil', 'fuels', 'sea-level', 'sea', 'temperature', 'renewableenergy', 'unfcc', 'cop', 'paris', 'intendednationallydeterminedcontribution', 'ipcc', 'intergovernmental', 'ppm', 'methane', 'pre-industrial', 'mitigation', 'fracking', 'climatechange', 'weather', 'heat', 'atmosphere', 'earth', 'preventativemeasures', 'preventative', 'carbon', 'ecosystem', 'energy', 'fuel', 'gas', 'oil', 'thermal', 'geosphere', 'biology', 'biofuel', 'biosphere', 'climate', 'weather', 'heat', 'atmosphere', 'adapt', 'life', 'earth', 'sun', 'sky', 'prevent', 'measures', 'preventative', 'innovation', 'carbon', 'ecosystem', 'energy', 'fuel', 'greenhouse', 'oil', 'carbon', 'waste', 'thermal', 'mitigation', 'efficiency', 'emissions', 'water', 'hydrogen', 'wave', 'gas', 'global', 'warming', 'temperature', 'geosphere', 'fossil', 'evaporation', 'biology', 'alternative', 'vapor', 'vulnerable', 'vulnerability']\n"
     ]
    }
   ],
   "source": [
    "with open('climate_vocab.txt') as f:\n",
    "    climate_vocab = f.read().lower().splitlines()\n",
    "    \n",
    "print(climate_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - datetime\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://repo.anaconda.com/pkgs/main/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/main/noarch\n",
      "  - https://repo.anaconda.com/pkgs/r/linux-64\n",
      "  - https://repo.anaconda.com/pkgs/r/noarch\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Install a conda package in the current Jupyter kernel\n",
    "import sys\n",
    "!conda install --yes --prefix {sys.prefix} datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import dask\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from edgar import Company, TXTML\n",
    "from edgar import Edgar\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import Word\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edgar(ll, n):\n",
    "    filinglist = []\n",
    "    for el in ll:\n",
    "        company = Company(el[0], el[1])\n",
    "        tree = company.get_all_filings(filing_type = \"10-K\")\n",
    "        docs = Company.get_documents(tree, no_of_documents=n, as_documents=True)\n",
    "        texts = Company.get_documents(tree, no_of_documents=n, as_documents=False)\n",
    "        if n<2:\n",
    "            docs=[docs]\n",
    "            texts=[texts]\n",
    "        for i in range(n):\n",
    "            date = docs[i].content['Filing Date']\n",
    "            dateStr = str(date)\n",
    "            year = date[:4]\n",
    "            text = TXTML.parse_full_10K(texts[i])\n",
    "            filinglist.append([el[0],el[1],date,year, text])\n",
    "    df = pd.DataFrame(filinglist, columns=['Company','CIK','Filing_Date','Year','TEXT'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tech companies\n",
    "tech_companies = [\n",
    "    ['Alphabet Inc.','0001652044'],\n",
    "    ['Apple Inc.', '0000320193'],\n",
    "    ['Microsoft Corp','0000789019'],\n",
    "    ['IBM Corp', '0000051143'],\n",
    "    ['INTEL CORP', \"50863\"]\n",
    "]\n",
    "\n",
    "tech_companiesDF = get_edgar(tech_companies,5)\n",
    "\n",
    "#financials companies\n",
    "fin_companies = [\n",
    "    ['Berkshire Hathaway','1067983'],\n",
    "    ['JPMORGAN CHASE & CO', '00000019617'],\n",
    "    ['FEDERAL NATIONAL MORTGAGE ASSOCIATION','310522'],\n",
    "    ['METLIFE INC', '1099219'],\n",
    "    ['CITIGROUP INC', '0000831001']\n",
    "]\n",
    "\n",
    "fin_companiesDF = get_edgar(fin_companies,5)\n",
    "\n",
    "#energy companies\n",
    "energy_companies = [\n",
    "    ['EXXON MOBIL CORP','0000034088'],\n",
    "    ['CHEVRON CORP', '0000093410'],\n",
    "    ['MARATHON OIL CORP','0000101778'],\n",
    "    ['Phillips 66', '0001534701'],\n",
    "    ['Energy Transfer LP', '0001276187']\n",
    "]\n",
    "\n",
    "energy_companiesDF = get_edgar(energy_companies,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean text function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(DF): \n",
    "    #lowercase\n",
    "    DF['TEXT'] = DF['TEXT'].apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "    #remove punctuation\n",
    "    DF['TEXT'] = DF['TEXT'].str.replace('[^\\w\\s]','').replace('/_/g', \"\")\n",
    "\n",
    "    #remove stopwords\n",
    "    DF['TEXT'] = DF['TEXT'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "\n",
    "    #remove numbers\n",
    "    DF['TEXT'] = DF['TEXT'].str.replace('\\d+', '')\n",
    "\n",
    "    #remove non-english words\n",
    "    nltk.download('words')\n",
    "    words = set(nltk.corpus.words.words())\n",
    "\n",
    "    DF['TEXT'] = DF['TEXT'].apply(lambda x: \" \".join(x for x in str(x).split() if x.lower() in words or not x.isalpha()))\n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tech\n",
    "tech_companiesDF = clean_text(tech_companiesDF)\n",
    "\n",
    "#financials\n",
    "fin_companiesDF = clean_text(fin_companiesDF)\n",
    "\n",
    "#energy\n",
    "energy_companiesDF = clean_text(energy_companiesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove frequent words function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#remove frequent words\n",
    "def remove_freq(DF):\n",
    "    freq = pd.Series(' '.join(DF['TEXT']).split()).value_counts()[:10]\n",
    "    freq\n",
    "\n",
    "    freq = list(freq.index)\n",
    "    DF['TEXT'] = DF['TEXT'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))\n",
    "    DF['TEXT'].head()\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tech\n",
    "remove_freq(tech_companiesDF)\n",
    "\n",
    "#energy\n",
    "remove_freq(energy_companiesDF)\n",
    "\n",
    "#financials\n",
    "remove_freq(fin_companiesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaned data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_companies = tech_companiesDF[['Company', 'CIK', 'Filing_Date', 'Year','TEXT']].sort_values(by='Filing_Date', ascending=True)\n",
    "\n",
    "energy_companies = energy_companiesDF[['Company', 'CIK', 'Filing_Date', 'Year','TEXT']].sort_values(by='Filing_Date', ascending=True)\n",
    "\n",
    "fin_companies = fin_companiesDF[['Company', 'CIK', 'Filing_Date', 'Year','TEXT']].sort_values(by='Filing_Date', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency of special words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create frequency of special words found in tech companies\n",
    "techfreqList = []\n",
    "for text in tech_companiesDF['TEXT']:\n",
    "    wordlist = text.split()\n",
    "    clean_words = []\n",
    "    for word in wordlist:\n",
    "        if word in climate_vocab:\n",
    "            clean_words.append(Word(re.sub(\"[^a-zA-Z]+\", \"\", word)).lemmatize())\n",
    "            \n",
    "    count = Counter(clean_words)\n",
    "    total = 0\n",
    "    for w, frequency in count.items():\n",
    "        total = total + frequency\n",
    "    techfreqList.append(total)\n",
    "    \n",
    "#Create frequency of special words found in energy companies\n",
    "energyfreqList = []\n",
    "for text in energy_companiesDF['TEXT']:\n",
    "    wordlist = text.split()\n",
    "    clean_words = []\n",
    "    for word in wordlist:\n",
    "        if word in climate_vocab:\n",
    "            clean_words.append(Word(re.sub(\"[^a-zA-Z]+\", \"\", word)).lemmatize())\n",
    "            \n",
    "    count = Counter(clean_words)\n",
    "    total = 0\n",
    "    for w, frequency in count.items():\n",
    "        total = total + frequency\n",
    "    energyfreqList.append(total)\n",
    "    \n",
    "#Create frequency of special words found in financial companies\n",
    "finfreqList = []\n",
    "for text in fin_companiesDF['TEXT']:\n",
    "    wordlist = text.split()\n",
    "    clean_words = []\n",
    "    for word in wordlist:\n",
    "        if word in climate_vocab:\n",
    "            clean_words.append(Word(re.sub(\"[^a-zA-Z]+\", \"\", word)).lemmatize())\n",
    "            \n",
    "    count = Counter(clean_words)\n",
    "    total = 0\n",
    "    for w, frequency in count.items():\n",
    "        total = total + frequency\n",
    "    finfreqList.append(total)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_companiesDF['Frequency'] = techfreqList\n",
    "\n",
    "energy_companiesDF['Frequency'] = energyfreqList\n",
    "\n",
    "fin_companiesDF['Frequency'] = finfreqList\n",
    "fin_companiesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing tech companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Generate Data\n",
    "tech_companiesDF['Year'] = tech_companiesDF['Year'].astype(int)\n",
    "tech_companiesDF.sort_values(by='Year', inplace=True, ascending=True)\n",
    "df = pd.DataFrame(dict(x= tech_companiesDF['Year'], y = tech_companiesDF['Frequency'], label = tech_companiesDF['Company']))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([2015,2021])\n",
    "ax.set_ylim([0,200])\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing energy companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "energy_companiesDF['Year'] = energy_companiesDF['Year'].astype(int)\n",
    "energy_companiesDF.sort_values(by='Year', inplace=True, ascending=True)\n",
    "df = pd.DataFrame(dict(x= energy_companiesDF['Year'], y = energy_companiesDF['Frequency'], label = energy_companiesDF['Company']))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([2015,2021])\n",
    "ax.set_ylim([0,700])\n",
    "ax.margins(0)\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing financial companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Data\n",
    "fin_companiesDF['Year'] = fin_companiesDF['Year'].astype(int)\n",
    "fin_companiesDF.sort_values(by='Year', inplace=True, ascending=True)\n",
    "df = pd.DataFrame(dict(x= fin_companiesDF['Year'], y = fin_companiesDF['Frequency'], label = fin_companiesDF['Company']))\n",
    "groups = df.groupby('label')-0[]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([2015,2021])\n",
    "ax.set_ylim([0,700])\n",
    "ax.margins(0)\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: OED Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OEDlist.txt') as f:\n",
    "    OEDclimate_vocab = f.read().lower().splitlines()\n",
    "\n",
    "#Create frequency of special words found in tech companies\n",
    "techfreqList = []\n",
    "for text in tech_companiesDF['TEXT']:\n",
    "    wordlist = text.split()\n",
    "    clean_words = []\n",
    "    for word in wordlist:\n",
    "        if word in OEDclimate_vocab:\n",
    "            clean_words.append(Word(re.sub(\"[^a-zA-Z]+\", \"\", word)).lemmatize())\n",
    "            \n",
    "    count = Counter(clean_words)\n",
    "    total = 0\n",
    "    for w, frequency in count.items():\n",
    "        total = total + frequency\n",
    "    techfreqList.append(total)\n",
    "    \n",
    "#Create frequency of special words found in energy companies\n",
    "energyfreqList = []\n",
    "for text in energy_companiesDF['TEXT']:\n",
    "    wordlist = text.split()\n",
    "    clean_words = []\n",
    "    for word in wordlist:\n",
    "        if word in OEDclimate_vocab:\n",
    "            clean_words.append(Word(re.sub(\"[^a-zA-Z]+\", \"\", word)).lemmatize())\n",
    "            \n",
    "    count = Counter(clean_words)\n",
    "    total = 0\n",
    "    for w, frequency in count.items():\n",
    "        total = total + frequency\n",
    "    energyfreqList.append(total)\n",
    "    \n",
    "#Create frequency of special words found in financial companies\n",
    "finfreqList = []\n",
    "for text in fin_companiesDF['TEXT']:\n",
    "    wordlist = text.split()\n",
    "    clean_words = []\n",
    "    for word in wordlist:\n",
    "        if word in OEDclimate_vocab:\n",
    "            clean_words.append(Word(re.sub(\"[^a-zA-Z]+\", \"\", word)).lemmatize())\n",
    "            \n",
    "    count = Counter(clean_words)\n",
    "    total = 0\n",
    "    for w, frequency in count.items():\n",
    "        total = total + frequency\n",
    "    finfreqList.append(total)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphing changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# TECH\n",
    "tech_companiesDF['Year'] = tech_companiesDF['Year'].astype(int)\n",
    "tech_companiesDF.sort_values(by='Year', inplace=True, ascending=True)\n",
    "df = pd.DataFrame(dict(x= tech_companiesDF['Year'], y = tech_companiesDF['Frequency'], label = tech_companiesDF['Company']))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([2015,2021])\n",
    "ax.set_ylim([0,200])\n",
    "ax.margins(0.05)\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ENERGY\n",
    "energy_companiesDF['Year'] = energy_companiesDF['Year'].astype(int)\n",
    "energy_companiesDF.sort_values(by='Year', inplace=True, ascending=True)\n",
    "df = pd.DataFrame(dict(x= energy_companiesDF['Year'], y = energy_companiesDF['Frequency'], label = energy_companiesDF['Company']))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([2015,2021])\n",
    "ax.set_ylim([0,700])\n",
    "ax.margins(0)\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# FINANCIALS\n",
    "fin_companiesDF['Year'] = fin_companiesDF['Year'].astype(int)\n",
    "fin_companiesDF.sort_values(by='Year', inplace=True, ascending=True)\n",
    "df = pd.DataFrame(dict(x= fin_companiesDF['Year'], y = fin_companiesDF['Frequency'], label = fin_companiesDF['Company']))\n",
    "groups = df.groupby('label')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax = plt.gca()\n",
    "ax.set_xlim([2015,2021])\n",
    "ax.set_ylim([0,700])\n",
    "ax.margins(0)\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.x, group.y, marker='o', linestyle='', ms=12, label=name)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
